{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ExAI - Corgy seperator üê∂\n",
        "\n",
        "We use [Contrastive GradCAM](https://xai-blog.netlify.app/docs/groups/contrastive-grad-cam-consistency/#contrastive-grad-cam-consistency-loss)\n",
        "and [Layerwise Relevance Propagation](https://github.com/kaifishr/PyTorchRelevancePropagation) to explain the difference between Corgys and Cardigans.\n",
        "\n",
        " - We leverage [Standford ImageNet Dog Dataset](http://vision.stanford.edu/aditya86/ImageNetDogs/) for fintuning [ResNet](https://pytorch.org/hub/pytorch_vision_resnet/#model-description).\n",
        "\n"
      ],
      "metadata": {
        "id": "GSjCu3qxLzNK"
      },
      "id": "GSjCu3qxLzNK"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "SJYyGFcNMcRI",
        "outputId": "6b0a23f3-ef0f-4fa2-82ae-a8834f0d5a3e",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "/\n",
            "Mounted at /content/drive\n",
            "-= Done =-\n"
          ]
        }
      ],
      "source": [
        "# If you want to persist data, you have to store it on g-drive or github.\n",
        "# ..unfortunately you have to connect to g-drive manually (once every session).\n",
        "#@title ‚ú≥Ô∏è Setup Google Drive for persistent storage\n",
        "\n",
        "OPTIONS = {}\n",
        "\n",
        "USE_GOOGLE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "\n",
        "if USE_GOOGLE_DRIVE:\n",
        "    !echo \"Mounting Google Drive...\"\n",
        "    %cd /\n",
        "\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "!echo -= Done =-\n"
      ],
      "id": "SJYyGFcNMcRI"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id",
        "outputId": "6c3b9c7f-2926-4caf-e2a3-84370e60329b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded images.tar to /content/drive/MyDrive/xAI-Corgis/images.tar\n"
          ]
        }
      ],
      "source": [
        "#@title Download training data [once]\n",
        "\n",
        "TRAINING_SETS_TARGET = \"/content/drive/MyDrive/xAI-Corgis\" # @param{type:\"string\"}\n",
        "\n",
        "import os\n",
        "import requests\n",
        "\n",
        "def download_data(url, path):\n",
        "    \"\"\"\n",
        "    Downloads data from a given URL and stores it in a designated path.\n",
        "\n",
        "    Args:\n",
        "        url: The URL of the data to download.\n",
        "        path: The path to store the downloaded data.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create the directory if it doesn't exist\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "\n",
        "    # Download the data\n",
        "    response = requests.get(url, stream=True)\n",
        "    response.raise_for_status()  # Raise an exception for bad status codes\n",
        "\n",
        "    # Save the data to the specified path\n",
        "    filename = os.path.basename(url)\n",
        "    filepath = os.path.join(path, filename)\n",
        "\n",
        "    with open(filepath, 'wb') as file:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            file.write(chunk)\n",
        "\n",
        "    print(f\"Downloaded {filename} to {filepath}\")\n",
        "\n",
        "\n",
        "os.makedirs(TRAINING_SETS_TARGET, exist_ok=True)\n",
        "\n",
        "download_data(\"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\", TRAINING_SETS_TARGET)\n",
        "# download_data(\"http://vision.stanford.edu/aditya86/ImageNetDogs/train_data.mat\", TRAINING_SETS_TARGET)\n",
        "# download_data(\"http://vision.stanford.edu/aditya86/ImageNetDogs/test_data.mat\", TRAINING_SETS_TARGET)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1. Prepare fine tuning of ResNet50 in PyTorch\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import scipy.io as sio\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Assuming you have the .mat files downloaded as shown in the previous code.\n",
        "\n",
        "# Define paths to your .mat files\n",
        "train_data_path = os.path.join(TRAINING_SETS_TARGET, 'train_data.mat')\n",
        "test_data_path = os.path.join(TRAINING_SETS_TARGET, 'test_data.mat')\n",
        "\n",
        "# Custom Dataset class to handle .mat files\n",
        "class MatDataset(Dataset):\n",
        "    def __init__(self, mat_file_path, transform=None, image_field_name=\"images\", label_fiels_name=\"labels\"):\n",
        "      \"\"\"\n",
        "        Please make sure your field_names in your .mat file are according to source, wont be checked!\n",
        "      \"\"\"\n",
        "      self.data = sio.loadmat(mat_file_path) # Load .mat file using scipy.io\n",
        "      self.images = self.data[image_field_name] # Adapt based on actual .mat structure\n",
        "      self.labels = self.data[label_fiels_name] # \"\n",
        "      self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      image = self.images[idx]\n",
        "      label = self.labels[idx]\n",
        "\n",
        "      if self.transform:\n",
        "          image = self.transform(image)\n",
        "      return image, label\n",
        "\n",
        "# Data preprocessing and augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create datasets and dataloaders\n",
        "train_dataset = MatDataset(train_data_path, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_dataset = MatDataset(test_data_path, transform=transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Load pre-trained ResNet50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Modify the final fully connected layer for your specific number of classes\n",
        "num_classes = len(set(train_dataset.labels)) # Replace with your number of classes\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "# Define loss function, optimizer, and device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using following device: {device}\")\n",
        "\n",
        "# load..\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "X71aR-0Y5O-7"
      },
      "id": "X71aR-0Y5O-7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2. Run Fine-tuning\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Fine-tuning loop\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
        "\n",
        "# Evaluation (example)\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"Accuracy on test data: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "id": "o-2VF4oKDqRw"
      },
      "id": "o-2VF4oKDqRw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Save the finetuned model\n",
        "torch.save(model.state_dict(), 'resnet50_finetuned.pth')"
      ],
      "metadata": {
        "id": "TssTfUXeH_C_"
      },
      "id": "TssTfUXeH_C_",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}